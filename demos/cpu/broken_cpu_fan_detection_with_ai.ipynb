{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91919529-aef8-4ced-99ea-8cdd3823e360",
   "metadata": {},
   "source": [
    "# Detection of broken CPU fan with the use of IA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8355b0-b83e-483d-8330-87a7cae6145a",
   "metadata": {},
   "source": [
    "We have computers and we want to know whether their cpu is broken or not.   \n",
    "To be able to know that we use the model of the digital twin to create a model of the cpu.   \n",
    "The digital twin is a way to modelize something material with a program and visualize it on the computer.  \n",
    "This model allows us to create a lot of data that we will use to train an artificial intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f5abcf-cc70-41e2-929e-4d54f72e09d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b144b9a0-6eae-417c-ab10-b740cb6b829e",
   "metadata": {},
   "source": [
    "To do so we need some packages:   \n",
    "- numpy\n",
    "- pandas to generate and manipulate dataframe\n",
    "- plotly.graph_objects to generate interactive graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5747fd-157c-41f8-99db-99aaa4b46e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f309ffc4-66a0-48d5-9946-989d888cdc0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e782e610-d02a-4bdd-b809-986102f8779c",
   "metadata": {},
   "source": [
    "To create our datasets we used two digital twins of a cpu made up of a fan, a cpu, a heat exchanger and a controler. The first is working without issue, the second has a broken fan and can't cool the cpu.      The simulation is a usage of 100% for 20 seconds and then 0% for 10 seconds. We take the temperature of the cpu after those 30 seconds.   \n",
    "\n",
    "We then run each digital twins for one thousand air temperature points (with the same distance between two adjacent points) from 0 to 30Â°C, for a total of two thousand cases. We then choose randomly 200 samples of the broken twin and 800 from the one working.   \n",
    "To avoid giving the exact same data in the training and testing sets we won't use the same number of points when running the digital twins: for the test set we will make one thousand and one. We then get the two thousand first cases (one thousand broken and the others working) to create our test set.   \n",
    "The data given in the dataset impact the way our neural network learns. Try to change the dataset: number, pourcentage of each class...   \n",
    "\n",
    "The data in our datasets are: the temperature of the air, the temperature of the cpu and the tension that should be used to make the fan spin.\n",
    "\n",
    "We use the notebook DatasetCreationLinearDoE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e093e808-93d3-4921-9b35-258a9777cb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(f\"./data/dataset_999_cases_20_percent_broken.csv\")\n",
    "testset = pd.read_csv(f\"./data/test_set_1000_cases_20_percent_broken.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e949bfac-a286-45df-bb3f-6f6dd65a5cd5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clear and create datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7473a0fd-8f3a-470b-b9f3-3945f1ac9a2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### We create the training sets: Xtrain (the data that the neural network will use to learn and determine how to predict a class when we give it data) and ytrain (the classes of the data).   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c1e43c-15a6-466e-9b19-43b78c05a656",
   "metadata": {},
   "source": [
    "Working contains the classes so we drop it for Xtrain, and we keep it for ytrain while dropping all others columns.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79af3887-ed33-4150-bfb5-5af78add7d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = dataset.drop(\"working\", axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a19c66-bbb2-47d7-b568-5f0abd148d1f",
   "metadata": {},
   "source": [
    "We centralize the values of Xtrain by columns and keep the values of its mean and its standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19eaa7b-481c-449b-9072-54fbb6732d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xmean = Xtrain.mean()\n",
    "Xstd = Xtrain.std()\n",
    "Xtrain = (Xtrain-Xmean)/Xstd\n",
    "Xtrain = Xtrain.fillna(0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feacf66d-fbba-49ab-aa82-400d76d488f5",
   "metadata": {},
   "source": [
    "We create ytrain that contains the class of each case: we drop every columns other than Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ae2f8a-15db-428b-827b-fdcb10db47a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = dataset.drop([\"T_cpu\", \"fan.T_air\", \"fan.tension\"], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cf6bf7-3f99-4004-a033-1543da862eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We then make numpy array from Xtrain and ytrain to be able to use them later.\n",
    "Xtrain = Xtrain.to_numpy()\n",
    "ytrain = ytrain.to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0611817e-7cdc-4549-ae26-a602c1bdf29d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### We create the test sets: Xtest (the data that the neural network will use to predict a class) and ytest (the classes of the test data we want to determine).   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2a29eb-c252-4eee-b2d1-4b91b246f819",
   "metadata": {},
   "source": [
    "We drop the columns the same way we did for Xtrain and ytrain.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030547cb-863a-46e9-ad3c-1405f260b9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = testset.drop(\"working\", axis=\"columns\")\n",
    "ytest = testset.drop([\"T_cpu\", \"fan.T_air\", \"fan.tension\"], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6734d4ef-e4c6-4b94-86c2-424d816b8cb7",
   "metadata": {},
   "source": [
    "We also centralize the values of Xtest with the mean and standard deviation of **Xtrain**, not Xtest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9e2bc3-c9e5-4ccb-8e6b-fb0bb1b990fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = (Xtest - Xmean) / Xstd\n",
    "Xtest = Xtest.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbc952d-abab-42bb-a384-13ca2328e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We then make numpy array from Xtest and ytest.\n",
    "Xtest = Xtest.to_numpy()\n",
    "ytest = ytest.to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7750f9-c62f-4ce6-8320-e06db67c5f3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create and train the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6756b5-3a9e-4529-b5df-066c90c1c114",
   "metadata": {},
   "source": [
    "Here we create our neural network using the MLPClassifier function from sklearn.   \n",
    "The solver is the solver for weight optimization. There are 3 choices: lbfgs, an optimizer in the family of quasi-Newton methods, sgd: stochastic gradient descent and adam a stochastic gradient-based optimizer.   \n",
    "random_state is here to control the random number generator used and know if our neuralNetwork really improved after we modified it. It could have been an unlucky then lucky random number generator. You can try 99 to see a huge difference.   \n",
    "The lenght of the hidden_layer parameter is the number of layer of neuron and the ith number is the number of the ith layer.   \n",
    "verbose=False is to avoid seeing the result of each iteration: if True it gives the loss of each iteration.   \n",
    "shuffle=True is to shuffle or not the data at each iteration.   \n",
    "max_iter: the maximum number of iteration if the neural network doesn't stop before (default: 200, try putting 300 to see it stop by itself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740a8ecb-e3ed-47bd-b028-f9c4c73876d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralNetwork = MLPClassifier(solver='sgd', random_state=1, hidden_layer_sizes=(10, 10, 10, 10), verbose=False, shuffle=True, max_iter=200)\n",
    "neuralNetwork.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a539beb-2189-4b1c-a02a-51c4763cf1a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c5f34c-c24a-47e9-b95d-4e2fb1c5c575",
   "metadata": {},
   "source": [
    "We will predict the class of the data from Xtest and collect the probabilities for each class to study them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c467ab-95f4-4671-bf4d-52d27794fda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = neuralNetwork.predict(Xtest) #the classes\n",
    "y_prediction_probas = neuralNetwork.predict_proba(Xtest) #the probabilities for each classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10d6740-0d15-4644-91b9-d52b8a78f00b",
   "metadata": {},
   "source": [
    "y_prediction_probas is the liste of probabilities for each line in Xtest. Here it has 2 columns, each for  class, representing their probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ab61c6-e601-4994-a6f4-ce25d79018f7",
   "metadata": {},
   "source": [
    "Each column corresponds to one class. There are the same number of columns as the number of classes, in our case we have two classes so two columns.   \n",
    "Each line corresponds to one points.   \n",
    "Here the value of the first column of the kth line corresponds to the probability that the kth point is broken. The value of the second column of the same line is the probability that the point is working without issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa6544c-05e0-46fe-9404-1025cd849496",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction_probas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4bac62-4a6b-4e81-98ca-1acefed91bd2",
   "metadata": {},
   "source": [
    "Creation of mask allowing us to check the class of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157530de-9d59-40e2-9cbc-93df47c456b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "maskNoProblem = testset[\"working\"]==True\n",
    "maskBroken = testset[\"working\"]==False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035a1a8f-dea5-4994-923d-7a87c1c2bef0",
   "metadata": {},
   "source": [
    "We check the percentage of right answers of our model: one way to check if it works or not. However we do NOT know if for the neural network it has 50.1% or 100% probability to be the class given. We only know which one has the higher probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7b4437-ee6e-470b-b38a-ecfcded66328",
   "metadata": {},
   "source": [
    "What we want to get as a result here is a 100% precision: the neural network gave us the right answer for each points of the test set.   \n",
    "If we didn't get 100% precision and want to improve it we have to improve our neural network: either add one or more layer or change the number of neuron for the layers we already have.   \n",
    "For other dataset we won't have 100% but we will want to get the closer we can to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df552dd1-23b4-49d4-a6cc-7f1535845770",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\"Percentage of right guesses:\", neuralNetwork.score(Xtest, ytest)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e972f15-cdbd-4411-ab2f-be4d39d07f55",
   "metadata": {},
   "source": [
    "To check how much our network is accurate when giving a class we create and use a function to display various statistics: median, mean, standard deviation, minimum and maximum.   \n",
    "In our case we have a 100% precision so we can take every points. If we didn't we would have taken only the points where the neural network gave the right answer.   \n",
    "We want to have a median, a mean, a minimum and a maximum as high as possible and a standard deviation as low as possible. To improve them we can modify the neural network the same way we can do it for the guess precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b5fae8-553f-4518-99de-738b9bf67775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stats(arr):\n",
    "    return dict(median=np.median(arr)*100, mean=np.mean(arr)*100, std=np.std(arr)*100, min=np.min(arr)*100, max=np.max(arr)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c84156-94dd-4e29-9122-b76a89e4402d",
   "metadata": {},
   "source": [
    "Stats of dysfunctional cpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf57b6c4-41ec-4f80-ab5e-6301d73caaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_stats(y_prediction_probas[maskBroken][:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef581ed4-558f-4269-b7ff-7809a7a82d68",
   "metadata": {},
   "source": [
    "Stats of working cpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d62a673-0156-42b5-8698-222dd452bfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_stats(y_prediction_probas[maskNoProblem][:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1bb6b0-610e-4eb0-a999-84501d60ba44",
   "metadata": {},
   "source": [
    "We plot probability(Temp) for each type of cpu.   \n",
    "That is the probability given by the neural network to the right class for each point we gave it in the test set.   \n",
    "We want them to be the higher possible and that corresponds to be close to 1 on this graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae910e9d-bb6b-4ae3-afa1-6c5f437db0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Broken\":y_prediction_probas[maskBroken][:,0], \"No problem\":y_prediction_probas[maskNoProblem][:,1],\"Temp\":testset[maskNoProblem][\"fan.T_air\"]})\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df[\"Temp\"], y=df[\"Broken\"], mode='markers', name=\"Broken\"))\n",
    "fig.add_trace(go.Scatter(x=df[\"Temp\"], y=df[\"No problem\"], mode='markers', name=\"No problem\"))\n",
    "fig.layout = go.Layout(\n",
    "    title = {'text': 'Percentage of prediction function of temperature of air', 'font': {'size': 34}, 'x': 0.5},\n",
    "    width = 1200,\n",
    "    height = 600,\n",
    "    xaxis = {'title': {'text': 'Temperature of air', 'font': {'size': 20}}, 'gridcolor': '#EBF0F8'},\n",
    "    yaxis = {'title': {'text': 'Percentage of prediction', 'font': {'size': 20}}, 'gridcolor': '#EBF0F8'},\n",
    "    yaxis2 = {'title': {'text': 'weight (kg)', 'font': {'size': 20}}, 'side': \"right\", 'gridcolor': '#EBF0F8', \"overlaying\": \"y\"},\n",
    "    plot_bgcolor = 'white',\n",
    "    hovermode = 'x',\n",
    "    yaxis_range=[0,1]\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ff640d-5a50-453d-9c59-7d23760988d6",
   "metadata": {},
   "source": [
    "Boxplots of probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d6f070-08b4-41c8-a394-df4ee89ab9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentageNumbers(first, second, classes=[True, False], masks=[maskBroken, maskNoProblem]):\n",
    "    \n",
    "    firstGroup = [0]*len(classes)\n",
    "    secondGroup = [0]*len(classes)\n",
    "    lowGroup = [0]*len(classes)\n",
    "    wrongGroup = [0]*len(classes)\n",
    "    numberPerClass = [k.value_counts()[True] for k in masks]\n",
    "    print(numberPerClass)\n",
    "    \n",
    "    for k in range(len(masks)):\n",
    "        for i in range(len(y_prediction[masks[k]])):\n",
    "            #print(ytest[masks[k]][i], y_prediction[masks[k]][i], y_prediction_probas[masks[k]][i][k])\n",
    "            if ytest[masks[k]][i]!=y_prediction[masks[k]][i]:\n",
    "                wrongGroup[k]+=1\n",
    "            elif y_prediction_probas[masks[k]][i][k]>first:\n",
    "                firstGroup[k]+=1\n",
    "            elif y_prediction_probas[masks[k]][i][k]>second:\n",
    "                secondGroup[k]+=1\n",
    "            else:\n",
    "                lowGroup[k]+=1\n",
    "    return np.array(firstGroup)/np.array(numberPerClass), np.array(secondGroup)/np.array(numberPerClass), np.array(lowGroup)/np.array(numberPerClass), np.array(wrongGroup)/np.array(numberPerClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15d6744-7d17-4547-9994-6927c01113d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentageNumber = percentageNumbers(0.95,0.90)\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='95<', x=[\"Broken\", \"Working\"], y=percentageNumber[0], text=percentageNumber[0]),\n",
    "    go.Bar(name='90< <95', x=[\"Broken\", \"Working\"], y=percentageNumber[1], text=percentageNumber[1]),\n",
    "    go.Bar(name='<90', x=[\"Broken\", \"Working\"], y=percentageNumber[2], text=percentageNumber[2]),\n",
    "    go.Bar(name='Wrong', x=[\"Broken\", \"Working\"], y=percentageNumber[3], text=percentageNumber[3])\n",
    "])\n",
    "# Change the bar mode\n",
    "fig.update_layout(barmode='stack')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c98d024-662f-4cd0-bd69-eb3547fb4c43",
   "metadata": {},
   "source": [
    "As we only have two classes and we have a 100% prediction, if we plot an histogram of the probability of only one class we will have 2 groups on each side of the graph.   \n",
    "What we want to obtain in the best case is two 2 groups one at 0% and the other at 100%. As we don't have 100% precision for all the prediction we won't have only two groups at 0% and 100% but we will also have some at 0.1, 0.2 and 0.98."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9e7906-af6a-45a8-9d46-85b32bbd4587",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=y_prediction_probas[:,1],\n",
    "    histnorm='percent',\n",
    "    xbins=dict(\n",
    "        start=0,\n",
    "        end=1.0,\n",
    "        size=0.01\n",
    "    ),\n",
    "    opacity=0.7\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text='Precision of the prediction',\n",
    "    xaxis_title_text='Precision',\n",
    "    yaxis_title_text='Percentage of prediction',\n",
    "    bargap=0.2,\n",
    "    bargroupgap=0.1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
